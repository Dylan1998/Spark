{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38577af2-d648-4b03-82b5-f44adadae9b0",
   "metadata": {},
   "source": [
    "#### El cliente ha pedido realizar un ajuste a las reglas implementadas hasta ahora, estos ajustes consisten en reemplazar algunas funciones hechas con groupBy por funciones Window, presta mucha atención y resuelve las siguientes actividades.\n",
    "\n",
    "##### Nota: Para poder trabajar con este notebook es necesario haber terminado el ejercicio de las sesiones 06, 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c5e3c8-5689-4c7c-83d3-ec7b70d0e1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f34787-67c5-4d2b-a592-4f29e250e95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+-------------------------------------------------+----+\n",
      "|movie_id|title           |genres                                           |year|\n",
      "+--------+----------------+-------------------------------------------------+----+\n",
      "|1       |Toy Story (1995)|[Adventure, Animation, Children, Comedy, Fantasy]|1995|\n",
      "+--------+----------------+-------------------------------------------------+----+\n",
      "only showing top 1 row\n",
      "\n",
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|rating|time               |\n",
      "+-------+--------+------+-------------------+\n",
      "|1      |1       |4.0   |2008-11-03 11:52:19|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|tag   |time               |\n",
      "+-------+--------+------+-------------------+\n",
      "|224183 |832     |acting|2017-06-05 08:20:27|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "from pyspark.sql import SparkSession, DataFrame, Column, Window\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "\n",
    "# Creación de sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"ejercicio_8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Carga de tablas requeridas\n",
    "root_path = \"../resources/data/tmp/parquet/\"\n",
    "names_list = [\"06/movies\", \"06/ratings\", \"06/tags\"]\n",
    "df_dict = read_tmp_df(names_list)\n",
    "\n",
    "movies_df = df_dict[\"06/movies\"]\n",
    "ratings_df = df_dict[\"06/ratings\"]\n",
    "tags_df = df_dict[\"06/tags\"]\n",
    "\n",
    "movies_df.show(1, False)\n",
    "ratings_df.show(1, False)\n",
    "tags_df.show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07f716-9806-4388-ad1a-b0fa9f4266cf",
   "metadata": {},
   "source": [
    "#### Actividad 1:\n",
    "##### TO DO ->    En esta actividad hay que resolver la logica que implementaste en la \"Actividad 2 de la sesión 07 - método calculate_rating_values\" pero reemplazando el uso de la función groupBy por funciones Window. \n",
    "##### Tendrás que obtener el mismo resultado ya que en las validaciones se compararán ambos dataframes.\n",
    "##### La firma a utilizar es la siguiente:\n",
    "- ##### def calculate_rating_values_w(df: DataFrame) -> DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a5bb862-0181-4a7e-86bd-1611fe915f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "def calculate_rating_values_w(df: DataFrame) -> DataFrame:\n",
    "    window = Window.partitionBy(f.col(\"movie_id\"))\n",
    "    df = df.select(\n",
    "        f.col(\"movie_id\"),\n",
    "        f.round(f.avg(f.col(\"rating\")).over(window), 2).alias(\"avg_rating\"),\n",
    "        f.round(f.stddev_pop(f.col(\"rating\")).over(window), 2).alias(\"stddev_rating\"),\n",
    "        f.count(f.col(\"*\")).over(window).alias(\"count_rating\"),\n",
    "        f.min(f.col(\"time\")).over(window).alias(\"min_time_rating\")\n",
    "    ).distinct()\n",
    "    return df # modificar codigo interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f75654c-f84e-4c13-83f2-445301d53f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------+------------+-------------------+\n",
      "|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "|  100062|      3.63|         0.83|          64|2014-03-11 21:23:33|\n",
      "|  100070|      3.54|         0.89|          13|2013-01-24 11:24:50|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEjemplo de salida esperada:\\n+--------+----------+-------------+------------+-------------------+\\n|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\\n+--------+----------+-------------+------------+-------------------+\\n|  100062|      3.63|         0.83|          64|2014-03-11 21:23:33|\\n|  100070|      3.54|         0.89|          13|2013-01-24 11:24:50|\\n+--------+----------+-------------+------------+-------------------+\\nonly showing top 2 rows\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "calculate_rating_values_w(ratings_df).show(2)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada:\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "|  100062|      3.63|         0.83|          64|2014-03-11 21:23:33|\n",
    "|  100070|      3.54|         0.89|          13|2013-01-24 11:24:50|\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec544e2-6d98-427f-a16a-f74588d26ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "rating_values_df = calculate_rating_values_w(ratings_df)\n",
    "\n",
    "assert type(rating_values_df) == DataFrame\n",
    "assert len(rating_values_df.columns) == 5\n",
    "assert rating_values_df.count() == 83239\n",
    "\n",
    "data = rating_values_df \\\n",
    "    .filter(f.col(\"movie_id\") == \"296\") \\\n",
    "    .collect()[0]\n",
    "\n",
    "assert data[\"movie_id\"] == \"296\"\n",
    "assert data[\"avg_rating\"] == 4.19\n",
    "assert data[\"stddev_rating\"] == 0.95\n",
    "assert data[\"count_rating\"] == 108756\n",
    "assert data[\"min_time_rating\"] == datetime.datetime(1996, 2, 29, 10, 48, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "485c32fa-def0-4176-8d5e-50cf3358a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "dfs = [(rating_values_df, \"09/ratings\")]\n",
    "\n",
    "write_tmp_df(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4229ca-fada-466e-a2f7-fb10825867e1",
   "metadata": {},
   "source": [
    "#### Actividad 2:\n",
    "##### TO DO ->    En la siguiente celda se realiza la validación de que el contenido de la función desarrollada calculate_rating_values_w sea identico al contenido del dataframe correspondiente del ejercicio \"Actividad 2 de la sesión 07 - método calculate_rating_values\".\n",
    "##### Para realizar la validación nos apoyamos cualquiera de las siguientes funciones de la clase DataFrame:\n",
    "- subtract (en caso de spark-scala la función es except)-> https://spark.apache.org/docs/3.2.1/api/python/reference/api/pyspark.sql.DataFrame.subtract.html\n",
    "- exceptAll -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.exceptAll.html#pyspark.sql.DataFrame.exceptAll\n",
    "##### Estas funciones las vas a utilizar mucho en tus futuros proyectos, basicamente al aplicar la acción \"count\" al dataframe retornado de aplicar esta función (subtract o exceptAll) entre dos dataframes identicos el valor resultante debería ser cero.\n",
    "##### Asumimos que en este caso el resultado de subtract debería ser cero. En caso de que el valor resultante sea distinto de cero coloca las transformaciones necesarias para localizar qué registros tienen la diferencia y si es posible hacer una corrección, realizala en la \"Actividad 1\" (método calculate_rating_values_w) o simplemente justifica  la diferencia de ambos dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3fa20b-e7eb-4750-aeff-1f74c8688a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de diferencias del dataframe actual (ratings_values_09_df) vs dataframe de Actividad 2 sesion 07:  2\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "|   82356|      3.38|         0.63|          16|2010-12-09 13:07:28|\n",
      "|  194474|      3.63|         0.88|          16|2019-02-20 08:41:51|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "\n",
      "Conteo de diferencias del dataframe de Actividad 2 sesion 07 vs dataframe actual (ratings_values_09_df):  2\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "|  194474|      3.63|         0.87|          16|2019-02-20 08:41:51|\n",
      "|   82356|      3.38|         0.62|          16|2010-12-09 13:07:28|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "\n",
      "Justificación\n",
      " La desviación estándar es la que difiere, esto es por temas de redondeo, quiero suponer que varía la manera de hacer el cálculo de la desviación estándar ya que se hace un proceso de shuffle con el groupBy\n"
     ]
    }
   ],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "root_path = \"../resources/data/tmp/parquet/\"\n",
    "names_list = [\"07/ratings\", \"09/ratings\"]\n",
    "rates_dict = read_tmp_df(names_list)\n",
    "ratings_values_07_df = rates_dict[\"07/ratings\"]\n",
    "ratings_values_09_df = rates_dict[\"09/ratings\"]\n",
    "\n",
    "diff_01 = ratings_values_09_df.exceptAll(ratings_values_07_df)\n",
    "print(\"Conteo de diferencias del dataframe actual (ratings_values_09_df) vs dataframe de Actividad 2 sesion 07: \", diff_01.count())\n",
    "diff_01.show()\n",
    "diff_02 = ratings_values_07_df.exceptAll(ratings_values_09_df)\n",
    "print(\"Conteo de diferencias del dataframe de Actividad 2 sesion 07 vs dataframe actual (ratings_values_09_df): \", diff_02.count())\n",
    "diff_02.show()\n",
    "\n",
    "print(\"Justificación\\n La desviación estándar es la que difiere, esto es por temas de redondeo, quiero suponer que varía la manera de hacer el cálculo de la desviación estándar ya que se hace un proceso de shuffle con el groupBy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "287417fa-478c-444c-8d07-1bc8cc7ac142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Justificación\n",
      " La desviación estándar es la que difiere debido a la forma en la que se efectúa el cálculo, para este caso, con dos decimales se puede ver esta diferencia, si se emokean más decimales, sería complicado ver estas diferencias\n"
     ]
    }
   ],
   "source": [
    "## Aqui van tus transformación para revisar y/o justificar diferencias\n",
    "\n",
    "diff_01 # Transformaciones a diff_01 (Revisión)\n",
    "diff_02 # Transformaciones a diff_02 (Revisión)\n",
    "print(\"Justificación\\n La desviación estándar es la que difiere debido a la forma en la que se efectúa el cálculo, para este caso, con dos decimales se puede ver esta diferencia, si se emokean más decimales, sería complicado ver estas diferencias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7f23a-b777-44d4-ae7e-fe6308e6a8c1",
   "metadata": {},
   "source": [
    "#### Actividad 3:\n",
    "##### TO DO ->    En esta actividad hay que resolver la logica que implementaste en la \"Actividad 3 de la sesión 07 - métodos get_act_3_df1 y get_act_3_df2\" pero reemplazando el uso de la función groupBy por funciones Window. \n",
    "##### Tendrás que obtener el mismo resultado ya que en las validaciones se compararán ambos dataframes.\n",
    "##### La firma a utilizar es la siguiente:\n",
    "- ##### Primer tabla (utilizando función concat_ws o concat): def get_act_3_df1_w(df: DataFrame) -> DataFrame:\n",
    "- ##### Segunda tabla (utilizando función struct): def get_act_3_df2_w(df: DataFrame) -> DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c013c1e-f140-45b1-ba93-336aef9acedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TU CODIGO VA EN ESTA CELDA, PUEDES GENERAR MÉTODOS O VARIABLES NUEVAS SI ASI LO REQUIERES\n",
    "\n",
    "def get_act_3_df1_w(df: DataFrame):\n",
    "    window_1 = Window.partitionBy(f.col(\"movie_id\"))\n",
    "\n",
    "    df = df.select(\n",
    "        *difference(tags_df.columns,[\"tag\"]),\n",
    "        f.upper(f.col(\"tag\")).alias(\"tag\")\n",
    "        )\n",
    "    window_2 = Window.partitionBy(f.col(\"movie_id\"),f.col(\"tag\"))\n",
    "    df = df.select(\n",
    "        f.col(\"movie_id\"),\n",
    "        f.col(\"tag\"),\n",
    "        f.count(\"tag\").over(window_2).alias(\"count\"),\n",
    "        f.min(f.col(\"time\")).over(window_1).alias(\"min\")\n",
    "    ).distinct()\n",
    "    df = df.select(\n",
    "        f.col(\"movie_id\"),\n",
    "        f.col(\"min\"),\n",
    "        f.concat_ws(\":\", f.col(\"tag\"), f.col(\"count\").cast(t.StringType())).alias(\"tag_count\")\n",
    "    )\n",
    "    df = df.select(\n",
    "        f.col(\"movie_id\"),\n",
    "        f.collect_set(f.col(\"tag_count\")).over(window_1).alias(\"tag_count\"),\n",
    "        f.min(f.col(\"min\")).over(window_1).alias(\"min_time_tag\")\n",
    "    ).distinct()\n",
    "    \n",
    "    df = df.select(\n",
    "        f.col(\"movie_id\"),\n",
    "        f.sort_array(f.col(\"tag_count\")).alias(\"tag_count\"),\n",
    "        f.col(\"min_time_tag\")\n",
    "    )\n",
    "    return df  # ... transformaciones a tags_df\n",
    "\n",
    "def get_act_3_df2_w(df: DataFrame):\n",
    "    window_1 = Window.partitionBy(f.col(\"movie_id\"))\n",
    "    df = df.select(\n",
    "        *difference(tags_df.columns,[\"tag\"]),\n",
    "        f.upper(f.col(\"tag\")).alias(\"tag\")\n",
    "        )\n",
    "\n",
    "    window_2 = Window.partitionBy(f.col(\"movie_id\"),f.col(\"tag\"))\n",
    "\n",
    "    df = df.select(\n",
    "        f.col(\"movie_id\"),\n",
    "        f.col(\"tag\"),\n",
    "        f.count(\"tag\").over(window_2).alias(\"count\"),\n",
    "        f.min(f.col(\"time\")).over(window_1).alias(\"min\")\n",
    "    ).distinct()\n",
    "\n",
    "    df = df.select(\n",
    "        f.col(\"movie_id\"),\n",
    "        f.collect_set(f.struct(f.col(\"tag\"), f.col(\"count\"))).over(window_1).alias(\"tag_count\"),\n",
    "        f.min(f.col(\"min\")).over(window_1).alias(\"min_time_tag\")\n",
    "    ).distinct()\n",
    "\n",
    "    df = df.select(\n",
    "        f.col(\"movie_id\"),\n",
    "        f.sort_array(f.col(\"tag_count\")).alias(\"tag_count\"),\n",
    "        f.col(\"min_time_tag\")\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "act_3_df1 = get_act_3_df1_w(tags_df)\n",
    "act_3_df2 = get_act_3_df2_w(tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b76900e-7ba9-4d99-bb20-2540cca7d4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------------------------------------------+-------------------+\n",
      "|movie_id|tag_count                                                 |min_time_tag       |\n",
      "+--------+----------------------------------------------------------+-------------------+\n",
      "|100062  |[FATE:1, PRESS-GANGED:1, WAR:1, WORLD WAR II:1]           |2018-05-26 17:40:54|\n",
      "|100070  |[COMEDIAN:2, COMEDY:1, GOOD HUMOUR:1, STRUGGLING CAREER:1]|2017-05-19 18:17:36|\n",
      "+--------+----------------------------------------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "|movie_id|tag_count                                                             |min_time_tag       |\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "|100062  |[{FATE, 1}, {PRESS-GANGED, 1}, {WAR, 1}, {WORLD WAR II, 1}]           |2018-05-26 17:40:54|\n",
      "|100070  |[{COMEDIAN, 2}, {COMEDY, 1}, {GOOD HUMOUR, 1}, {STRUGGLING CAREER, 1}]|2017-05-19 18:17:36|\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEjemplo de salida esperada:\\n+--------+------------------------------------------------------------------+-------------------+\\n|movie_id|tag_count                                                         |min_time_rating    |\\n+--------+------------------------------------------------------------------+-------------------+\\n|100062  |[PRESS-GANGED : 1, WORLD WAR II : 1, WAR : 1, FATE : 1]           |2018-05-26 16:40:54|\\n|100070  |[GOOD HUMOUR : 1, STRUGGLING CAREER : 1, COMEDY : 1, COMEDIAN : 2]|2017-05-19 17:17:36|\\n+--------+------------------------------------------------------------------+-------------------+\\nonly showing top 2 rows\\n\\n+--------+----------------------------------------------------------------------+-------------------+\\n|movie_id|tag_count                                                             |min_time_rating    |\\n+--------+----------------------------------------------------------------------+-------------------+\\n|100062  |[{PRESS-GANGED, 1}, {WORLD WAR II, 1}, {WAR, 1}, {FATE, 1}]           |2018-05-26 16:40:54|\\n|100070  |[{GOOD HUMOUR, 1}, {STRUGGLING CAREER, 1}, {COMEDY, 1}, {COMEDIAN, 2}]|2017-05-19 17:17:36|\\n+--------+----------------------------------------------------------------------+-------------------+\\nonly showing top 2 rows\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "act_3_df1.show(2, False)\n",
    "act_3_df2.show(2, False)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada:\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "|movie_id|tag_count                                                         |min_time_rating    |\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "|100062  |[PRESS-GANGED : 1, WORLD WAR II : 1, WAR : 1, FATE : 1]           |2018-05-26 16:40:54|\n",
    "|100070  |[GOOD HUMOUR : 1, STRUGGLING CAREER : 1, COMEDY : 1, COMEDIAN : 2]|2017-05-19 17:17:36|\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "|movie_id|tag_count                                                             |min_time_rating    |\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "|100062  |[{PRESS-GANGED, 1}, {WORLD WAR II, 1}, {WAR, 1}, {FATE, 1}]           |2018-05-26 16:40:54|\n",
    "|100070  |[{GOOD HUMOUR, 1}, {STRUGGLING CAREER, 1}, {COMEDY, 1}, {COMEDIAN, 2}]|2017-05-19 17:17:36|\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "229650b4-a2d1-4c52-82e5-576defdfbb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "assert len(act_3_df1.columns) == 3\n",
    "assert \"movie_id\" in act_3_df1.columns\n",
    "assert \"tag_count\" in act_3_df1.columns\n",
    "assert \"min_time_tag\" in act_3_df1.columns\n",
    "assert schema_to_ddl(act_3_df1.select(\"movie_id\", \"tag_count\", \"min_time_tag\")) == 'movie_id STRING,tag_count ARRAY<STRING> NOT NULL,min_time_tag TIMESTAMP'\n",
    "\n",
    "assert len(act_3_df2.columns) == 3\n",
    "assert \"movie_id\" in act_3_df2.columns\n",
    "assert \"tag_count\" in act_3_df2.columns\n",
    "assert \"min_time_tag\" in act_3_df2.columns\n",
    "assert schema_to_ddl(act_3_df2.select(\"movie_id\", \"tag_count\", \"min_time_tag\")) == 'movie_id STRING,tag_count ARRAY<STRUCT<tag: STRING, count: BIGINT>> NOT NULL,min_time_tag TIMESTAMP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b9a39-e449-41be-a455-737bd5eaf9ef",
   "metadata": {},
   "source": [
    "#### Actividad 4:\n",
    "##### TO DO ->    En la siguiente celda se realiza la validación de que el dataframe retornado por la función desarrollada get_act_3_df2_w sea identico al contenido del dataframe correspondiente del ejercicio \"Actividad 3 de la sesión 07 - método get_act_3_df2\".\n",
    "##### Para realizar la validación nos apoyamos de cualquiera de las siguientes funciones de la clase DataFrame:\n",
    "- subtract (en caso de spark-scala la función es except)-> https://spark.apache.org/docs/3.2.1/api/python/reference/api/pyspark.sql.DataFrame.subtract.html\n",
    "- exceptAll -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.exceptAll.html#pyspark.sql.DataFrame.exceptAll\n",
    "##### Probablemente existan diferencias en la comparación de ambos dataframes, investiga por qué ocurren dichas diferencias y haz los ajustes necesarios en tu actividad 3 o en la celda donde se aplica la función subtract para que la diferencia mostrada sea cero.\n",
    "##### Probablemente requieras utilizar la siguiente función:\n",
    "- sort_array -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sort_array.html#pyspark.sql.functions.sort_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fc822e6-cb47-46cb-8bfa-bb1be6f60f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "dfs = [(act_3_df1, \"09/tags_p1\"),\n",
    "       (act_3_df2, \"09/tags_p2\")]\n",
    "\n",
    "write_tmp_df(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1846ee5-694b-49a2-bf53-dddb4cb249ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "root_path = \"../resources/data/tmp/parquet/\"\n",
    "names_list = [\"07/tags_p1\", \"07/tags_p2\", \"09/tags_p1\", \"09/tags_p2\"]\n",
    "rates_dict = read_tmp_df(names_list)\n",
    "tags_values_07_p1_df = rates_dict[\"07/tags_p1\"]\n",
    "tags_values_07_p2_df = rates_dict[\"07/tags_p2\"]\n",
    "tags_values_09_p1_df = rates_dict[\"09/tags_p1\"]\n",
    "tags_values_09_p2_df = rates_dict[\"09/tags_p2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ea2f98e-4c99-4049-b659-6bcf766e50bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de diferencias del dataframe actual (tags_values_09_p2_df) vs dataframe de Actividad 2 sesion 07:  0\n",
      "Conteo de diferencias del dataframe de Actividad 2 sesion 07 vs dataframe actual (tags_values_09_p2_df):  0\n"
     ]
    }
   ],
   "source": [
    "# Puedes modificar esta celda si asi lo requieres, también puedes modificar tu desarrollo en la actividad 3 (método get_act_3_df2_w). \n",
    "# Pudes aplicar algunas transformaciones a los dataframes tags_values_07_p2_df y tags_values_09_p2_df únicamente para reordenar datos.\n",
    "# El resultado de las operaciones count debe ser cero ya que ambos dataframes deberían contener la misma información.\n",
    "\n",
    "#Recuerda que si el conteo da cero entonces ambos dataframes son identicos.\n",
    "diff_01 = tags_values_07_p2_df.exceptAll(tags_values_09_p2_df)\n",
    "print(\"Conteo de diferencias del dataframe actual (tags_values_09_p2_df) vs dataframe de Actividad 2 sesion 07: \", diff_01.count())\n",
    "diff_02 = tags_values_09_p2_df.exceptAll(tags_values_07_p2_df)\n",
    "print(\"Conteo de diferencias del dataframe de Actividad 2 sesion 07 vs dataframe actual (tags_values_09_p2_df): \", diff_02.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb169d1e-6484-489b-a4da-c44936e8f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "assert diff_01.count() == 0\n",
    "assert diff_02.count() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81bf84ab-0b94-4dc6-829e-b683e337b304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+----+--------------------+-------------------+----------+-------------+------------+-------------------+\n",
      "|movie_id|               title|              genres|year|           tag_count|       min_time_tag|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
      "+--------+--------------------+--------------------+----+--------------------+-------------------+----------+-------------+------------+-------------------+\n",
      "|       1|    Toy Story (1995)|[Adventure, Anima...|1995|[{1990S, 1}, {200...|2006-01-12 19:19:35|      3.89|         0.93|       76813|1996-01-28 18:00:00|\n",
      "|       2|      Jumanji (1995)|[Adventure, Child...|1995|[{1860S, 1}, {196...|2006-01-13 14:14:30|      3.28|         0.96|       30209|1996-01-28 18:00:00|\n",
      "|       3|Grumpier Old Men ...|   [Comedy, Romance]|1995|[{ANN MARGARET, 1...|2006-01-16 00:28:45|      3.17|         1.02|       15820|1996-01-29 17:54:45|\n",
      "|       4|Waiting to Exhale...|[Comedy, Drama, R...|1995|[{BASED ON NOVEL ...|2007-08-13 16:04:13|      2.87|         1.11|        3028|1996-02-01 08:33:45|\n",
      "|       5|Father of the Bri...|            [Comedy]|1995|[{4TH WALL, 1}, {...|2006-01-12 15:49:34|      3.08|          1.0|       15801|1996-01-29 17:54:46|\n",
      "|       6|         Heat (1995)|[Action, Crime, T...|1995|[{1, 1}, {7.5-FIL...|2006-01-13 16:08:02|      3.86|         0.88|       31850|1996-02-01 08:34:00|\n",
      "|       7|      Sabrina (1995)|   [Comedy, Romance]|1995|[{AMERICAN ABROAD...|2006-01-12 15:51:23|      3.37|         0.96|       15596|1996-01-28 18:00:00|\n",
      "|       8| Tom and Huck (1995)|[Adventure, Child...|1995|[{19TH CENTURY, 1...|2007-07-02 18:07:15|      3.12|         0.99|        1584|1996-02-01 08:34:25|\n",
      "|       9| Sudden Death (1995)|            [Action]|1995|[{1990S, 1}, {ACT...|2006-06-05 02:08:31|       3.0|         0.97|        4563|1996-02-01 08:34:08|\n",
      "|      10|    GoldenEye (1995)|[Action, Adventur...|1995|[{007, 23}, {007 ...|2006-01-13 20:07:42|      3.43|         0.88|       34942|1996-01-28 18:00:00|\n",
      "|      11|American Presiden...|[Comedy, Drama, R...|1995|[{23.03.06, 1}, {...|2006-01-15 19:28:24|      3.66|         0.91|       20256|1996-01-28 18:00:00|\n",
      "|      12|Dracula: Dead and...|    [Comedy, Horror]|1995|[{ABANDONED CHAPE...|2006-01-23 10:56:20|      2.68|         1.14|        4715|1996-01-28 18:00:00|\n",
      "|      13|        Balto (1995)|[Adventure, Anima...|1995|[{1920S, 1}, {199...|2006-02-21 14:01:49|      3.36|          1.0|        2278|1996-02-02 06:33:34|\n",
      "|      14|        Nixon (1995)|             [Drama]|1995|[{1920S, 1}, {193...|2006-01-15 19:40:23|      3.43|         0.95|        6933|1996-01-29 17:54:59|\n",
      "|      15|Cutthroat Island ...|[Action, Adventur...|1995|[{1660S, 1}, {17T...|2006-02-06 08:26:17|      2.73|         1.09|        3249|1996-01-29 18:00:56|\n",
      "|      16|       Casino (1995)|      [Crime, Drama]|1995|[{1970S, 1}, {198...|2006-01-13 13:47:20|      3.83|         0.87|       23932|1996-01-29 17:54:44|\n",
      "|      17|Sense and Sensibi...|    [Drama, Romance]|1995|[{1800S, 1}, {181...|2006-01-12 15:51:36|      3.95|         0.97|       25248|1996-01-28 18:00:00|\n",
      "|      18|   Four Rooms (1995)|            [Comedy]|1995|[{4, 1}, {ACTOR D...|2006-01-17 13:48:44|      3.42|         1.03|        6688|1996-01-28 18:00:00|\n",
      "|      19|Ace Ventura: When...|            [Comedy]|1995|[{ACE VENTURA, 1}...|2006-01-14 11:45:43|      2.67|         1.17|       26642|1996-01-28 18:00:00|\n",
      "|      20|  Money Train (1995)|[Action, Comedy, ...|1995|[{ACTION HERO, 1}...|2006-02-21 14:55:18|      2.89|         0.94|        4771|1996-02-01 08:33:43|\n",
      "+--------+--------------------+--------------------+----+--------------------+-------------------+----------+-------------+------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "last_movies_df = movies_df \\\n",
    "    .join(tags_values_09_p2_df, [\"movie_id\"], \"left\") \\\n",
    "    .join(ratings_values_09_df, [\"movie_id\"], \"left\")\n",
    "\n",
    "last_movies_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7747f5-bf41-4a4d-a775-90cc9c75455a",
   "metadata": {},
   "source": [
    "#### Actividad 5:\n",
    "##### TO DO ->    La última actividad a realizar es la siguiente:\n",
    "- ##### El cliente nos ha solicitado generar una tabla donde se muestre el top de peliculas ranqueadas por genero, para realizar esto se realizan los siguientes pasos:\n",
    "    - ##### Las peliculas que entran a la parte del ranqueo deben cumplir con las siguientes condiciones:\n",
    "        -  count_rating > 1000\n",
    "        -  avg_rating >= 4.2\n",
    "        -  stddev_rating < 2\n",
    "    - #####  Descomponer la columna \"genres\" en una columna llamada \"genre\"\n",
    "    - ##### Agregar la columna \"top\" donde se asignará el valor de la función \"rank\" de Spark tomando las siguientes caracteristicas:\n",
    "        - particionar por: \"genre\"\n",
    "        - order por: avg_rating DESC, stddev_rating ASC, count_rating DESC\n",
    "##### El esquema resultante deberá ser:\n",
    "* |-- title: string\n",
    "* |-- year: integer\n",
    "* |-- genre: string\n",
    "* |-- top: integer se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d21f3657-54ba-4b2a-a139-1ba41daa8b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "last_movies_df = movies_df \\\n",
    "    .join(tags_values_09_p2_df, [\"movie_id\"], \"left\") \\\n",
    "    .join(ratings_values_09_df, [\"movie_id\"], \"left\")\n",
    "\n",
    "last_movies_df = last_movies_df \\\n",
    "    .select(\n",
    "        *last_movies_df.columns\n",
    "    ) \\\n",
    "    .where((f.col(\"count_rating\") > 1000) & (f.col(\"avg_rating\") >= 4.2) & (f.col(\"stddev_rating\") < 2))\n",
    "\n",
    "last_movies_df = last_movies_df \\\n",
    "    .select(\n",
    "        *difference(last_movies_df.columns, [\"genres\"]),\n",
    "        f.explode(f.col(\"genres\")).alias(\"genre\")\n",
    "    )\n",
    "\n",
    "window = Window.partitionBy(f.col(\"genre\")).orderBy(f.col(\"avg_rating\").desc(), f.col(\"stddev_rating\").asc(),\n",
    "                                                    f.col(\"count_rating\").desc())\n",
    "\n",
    "top_movies_df = last_movies_df \\\n",
    "    .select(\n",
    "        f.col(\"title\"),\n",
    "        f.col(\"year\"),\n",
    "        f.col(\"genre\"),\n",
    "        f.rank().over(window).alias(\"top\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a250478e-7fff-4384-bbbf-9ae81599285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---------+---+\n",
      "|               title|year|    genre|top|\n",
      "+--------------------+----+---------+---+\n",
      "|Band of Brothers ...|2001|   Action|  1|\n",
      "|Seven Samurai (Sh...|1954|   Action|  2|\n",
      "|   Fight Club (1999)|1999|   Action|  3|\n",
      "|Over the Garden W...|2013|Adventure|  1|\n",
      "|Seven Samurai (Sh...|1954|Adventure|  2|\n",
      "+--------------------+----+---------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEjemplo de salida esperada (hay que mantener mismo orden de columnas):\\n+--------------------+----+---------+---+\\n|               title|year|    genre|top|\\n+--------------------+----+---------+---+\\n|Band of Brothers ...|2001|   Action|  1|\\n|Seven Samurai (Sh...|1954|   Action|  2|\\n|   Fight Club (1999)|1999|   Action|  3|\\n|Over the Garden W...|2013|Adventure|  1|\\n|Seven Samurai (Sh...|1954|Adventure|  2|\\n+--------------------+----+---------+---+\\nonly showing top 5 rows\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "top_movies_df.show(5)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada (hay que mantener mismo orden de columnas):\n",
    "+--------------------+----+---------+---+\n",
    "|               title|year|    genre|top|\n",
    "+--------------------+----+---------+---+\n",
    "|Band of Brothers ...|2001|   Action|  1|\n",
    "|Seven Samurai (Sh...|1954|   Action|  2|\n",
    "|   Fight Club (1999)|1999|   Action|  3|\n",
    "|Over the Garden W...|2013|Adventure|  1|\n",
    "|Seven Samurai (Sh...|1954|Adventure|  2|\n",
    "+--------------------+----+---------+---+\n",
    "only showing top 5 rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e8d5a52-1f1a-4ade-ba04-41266a276ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert top_movies_df.orderBy(f.col(\"genre\").asc(), f.col(\"top\").asc()).collect() == top_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1fb6c-0735-43f4-a4e9-1c73e825e5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
